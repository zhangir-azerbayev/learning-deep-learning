{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 Linear Regression\n",
    "\n",
    "*Regression*: modeling the relationship between one or more independent variables and a dependent variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Model\n",
    "\n",
    "The linearity assumption says that the dependent variable can be expressed as  a weighted sum of features + a bias term. \n",
    "\\begin{equation}\n",
    "\\hat{y} = \\sum_{i=1}^n w_ix_i + b\n",
    "\\end{equation}\n",
    "Or, letting $\\mathbf{w}$ be a vector of the weights and $\\mathbf{X}$ a *design matrix* (where each row is a training example, each column is a feature, and we add a column of 1s) \n",
    "\\begin{equation}\n",
    "\\mathbf{\\hat{y}} = \\mathbf{Xw}. \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function \n",
    "The loss function is given by \n",
    "\\begin{equation}\n",
    "L(\\mathbf{w}) = \\frac{1}{2n}||\\mathbf{y}-\\mathbf{Xw}||^2\n",
    "\\end{equation}\n",
    "The goal of training is to find \n",
    "\\begin{equation}\n",
    "\\mathbf{w}^* = \\mathrm{arg min}_\\mathbf{w}L(\\mathbf{w})\n",
    "\\end{equation}\n",
    "\n",
    "This loss function specifies the MLE given the assumption of Gaussian noise. Assume that\n",
    "\\begin{equation}\n",
    "y = \\mathbf{w}^T\\mathbf{x} + \\epsilon \\text{ where } \\epsilon \\sim \\mathcal{N}(0, \\sigma^2)\n",
    "\\end{equation}\n",
    "We want to maximize \n",
    "\\begin{equation}\n",
    "p(\\mathbf{y}|\\mathbf{X}) = \\prod p(y^{(i)}\\mid \\mathbf{x}^{(i)})\n",
    "\\end{equation}\n",
    "In practice, it is easier to optimize the log-likelihood, and by convention we want to minimize rather than maximize, therefore we take the negative log-likelihood. \n",
    "\\begin{equation}\n",
    "-\\log P(\\mathbf{y}\\mid\\mathbf{X}) = \\frac{n}{2}\\log(2\\pi\\sigma^2) + \\frac{1}{2\\sigma^2}||\\mathbf{y} - \\mathbf{Xw}||^2. \n",
    "\\end{equation}\n",
    "Dropping everything that's independent of $\\mathbf{w}$, we get the loss function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analytic Solution\n",
    "Linear regression is one of the rare optimization problems with an analytic solution. \n",
    "\\begin{equation}\n",
    "\\mathbf{w}^* = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minibatch Stochastic Gradient Descent\n",
    "\n",
    "Almost every optimization algorithm used in deep learning is some variation of minibatch stochastic gradient descent. \n",
    "\n",
    "The basic idea of gradient descent is to find minima using the following iterative process \n",
    "\\begin{equation}\n",
    "\\mathbf{w}_{i+1} = \\mathbf{w}_i - \\eta\\nabla_\\mathbf{w}L(\\mathbf{w})\n",
    "\\end{equation}\n",
    "Where $\\eta$ is a hyperparameter called the *learning rate*. \n",
    "\n",
    "But computing $\\nabla_\\mathbf{w}L(\\mathbf{w})$ on each iteration is costly. Therefore, on each iteration, we sample a minibatch $\\mathcal{B}$ and estimate $\\nabla_\\mathbf{w}L(\\mathbf{w})$ using only the examples in $\\mathcal{B}$. The size of the minibatches is another hyperparameter. \n",
    "\n",
    "For notational convenience, let \n",
    "\\begin{equation}\n",
    "l^{(i)}(\\mathbf{w}) = \\frac{1}{2}(\\mathbf{\\hat{y}}^{(i)}-\\mathbf{y}^{(i)})^2\n",
    "\\end{equation}\n",
    "Then\n",
    "\\begin{equation}\n",
    "L(\\mathbf{w}) = \\frac{1}{n}\\sum l^{(i)}(\\mathbf{w})\n",
    "\\end{equation}\n",
    "Then minibatch stochastic gradient descent works as follows\n",
    "\\begin{equation}\n",
    "\\mathbf{w}_{i+1} = \\mathbf{w}_i - \\frac{\\eta}{|\\mathcal{B}|}\\sum_{i\\in\\mathcal{B}}\\partial_w l^{(i)}(\\mathbf{w}) = \\mathbf{w}_i - \\frac{\\eta}{|\\mathcal{B}|}\\sum_{i\\in\\mathcal{B}}\\mathbf{x}^{(i)}\\left(\\mathbf{w}^T\\mathbf{x}^{(i)} - \\mathcal{y}^{(i)}\\right)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization\n",
    "Consolidating costly `for` loops into fast matrix operations can speed up our code dramatically. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import random \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "We first generate synthetic data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthetic_data(w, num_examples): \n",
    "    X = torch.normal(0, 1, (num_examples, len(w) - 1))\n",
    "    ones = torch.ones((num_examples, 1))\n",
    "    X = torch.cat((ones, X), dim=1)\n",
    "    y = torch.matmul(X, w) \n",
    "    y += torch.normal(0, 0.01, y.shape)\n",
    "    return X, y.reshape((-1, 1))\n",
    "\n",
    "true_w = torch.tensor([4.2, 2, -3.4])\n",
    "\n",
    "features, labels = synthetic_data(true_w, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of the linear correlation between $y$ and $x_1$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f8ab87ce550>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(features[:, 2].numpy(), labels.numpy(), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates an iterable for minibatching. In practice, we want large minibatches to exploit parallelism. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0000,  1.2131,  1.7047,  0.8355],\n",
      "        [ 1.0000, -1.3691, -0.1269,  1.9027],\n",
      "        [ 1.0000, -1.5180,  1.8054, -4.9715],\n",
      "        [ 1.0000,  0.0821, -0.8942,  7.4092],\n",
      "        [ 1.0000, -1.1560, -0.9046,  4.9586],\n",
      "        [ 1.0000, -1.3528,  1.1894, -2.5501],\n",
      "        [ 1.0000,  0.4905, -0.5693,  7.1054],\n",
      "        [ 1.0000, -0.7782, -0.7976,  5.3427],\n",
      "        [ 1.0000,  0.4764, -0.7417,  7.6737],\n",
      "        [ 1.0000, -0.3064, -0.4127,  4.9992]])\n"
     ]
    }
   ],
   "source": [
    "def data_iter(batch_size, features, labels): \n",
    "    num_examples = len(features)\n",
    "    indices = list(range(num_examples))\n",
    "    random.shuffle(indices)\n",
    "    for i in range(0, num_examples, batch_size): \n",
    "        batch_indices = torch.tensor(\n",
    "            indices[i: min(i + batch_size, num_examples)])\n",
    "        yield features[batch_indices], labels[batch_indices]\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "for X, y in data_iter(batch_size, features, labels): \n",
    "    print(torch.cat((X, y), dim=1))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate initial values for weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0052],\n",
      "        [ 0.0051],\n",
      "        [-0.0093]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "w = torch.normal(0, 0.01, size = (3,1), requires_grad=True)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction function\n",
    "def linreg(X, w): \n",
    "    return torch.matmul(X, w)\n",
    "\n",
    "# Loss function\n",
    "def squared_loss(y_hat, y): \n",
    "    return (y_hat - y) ** 2 / 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sgd\n",
    "def sgd(params, lr, batch_size): \n",
    "    with torch.no_grad():\n",
    "        params -= lr * params.grad / batch_size\n",
    "        params.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main training loop: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = \n",
      " tensor([[0.0003],\n",
      "        [0.0158],\n",
      "        [0.0030]], requires_grad=True)\n",
      "epoch 1, loss 0.042364\n",
      "w = \n",
      " tensor([[ 3.9969],\n",
      "        [ 1.9199],\n",
      "        [-3.1999]], requires_grad=True)\n",
      "epoch 2, loss 0.000165\n",
      "w = \n",
      " tensor([[ 4.1907],\n",
      "        [ 1.9965],\n",
      "        [-3.3878]], requires_grad=True)\n",
      "epoch 3, loss 0.000050\n",
      "w = \n",
      " tensor([[ 4.2001],\n",
      "        [ 1.9995],\n",
      "        [-3.3986]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "lr = 0.03\n",
    "num_epochs = 3\n",
    "net = linreg \n",
    "loss = squared_loss \n",
    "\n",
    "\n",
    "w = torch.normal(0, 0.01, size = (3,1), requires_grad=True)\n",
    "print(\"w = \\n\", w)\n",
    "\n",
    "for epoch in range(num_epochs): \n",
    "    for X, y in data_iter(batch_size, features, labels): \n",
    "        l = loss(net(X, w), y)\n",
    "        l.sum().backward()\n",
    "        sgd(w, lr, batch_size)\n",
    "    with torch.no_grad(): \n",
    "        train_l = loss(net(features, w), labels)\n",
    "        print(f'epoch {epoch + 1}, loss {float(train_l.mean()):f}')\n",
    "    print(\"w = \\n\", w)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in estimating w:  tensor(0.0015, grad_fn=<CopyBackwards>)\n"
     ]
    }
   ],
   "source": [
    "# Error from true parameters\n",
    "print(\"Error in estimating w: \", (true_w - w.reshape(true_w.shape)).norm())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation using high-level API\n",
    "Modern deep learning frameworks provide a tremendous amount of automation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0436,  1.5685],\n",
      "        [ 1.0506, -0.0539],\n",
      "        [-1.0695,  0.2334],\n",
      "        ...,\n",
      "        [ 0.6333, -0.3347],\n",
      "        [ 0.5646, -0.2069],\n",
      "        [ 0.6530, -2.0888]])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from torch.utils import data\n",
    "from torch import nn\n",
    "\n",
    "# Discard the column of ones.\n",
    "features2 = features[:, 1:]\n",
    "print(features2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f8ab8717910>\n"
     ]
    }
   ],
   "source": [
    "# Constructs a PyTorch data iterator\n",
    "def load_array(data_arrays, batch_size, is_train=True):\n",
    "    dataset = data.TensorDataset(*data_arrays)\n",
    "    return data.DataLoader(dataset, batch_size, shuffle=is_train)\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "data_iter = load_array((features2, labels), batch_size)\n",
    "print(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-0.7709, -1.7309],\n",
       "         [-1.6253,  0.6268],\n",
       "         [-0.5295,  0.4740],\n",
       "         [-1.3796, -1.0639],\n",
       "         [ 2.5633,  0.3100],\n",
       "         [-0.7603, -0.2150],\n",
       "         [ 0.6449,  1.4843],\n",
       "         [-0.0240,  0.2031],\n",
       "         [ 0.6170,  0.3315],\n",
       "         [-0.4490,  0.5956]]),\n",
       " tensor([[ 8.5485],\n",
       "         [-1.1704],\n",
       "         [ 1.5159],\n",
       "         [ 5.0392],\n",
       "         [ 8.2753],\n",
       "         [ 3.4158],\n",
       "         [ 0.4368],\n",
       "         [ 3.4495],\n",
       "         [ 4.3073],\n",
       "         [ 1.2972]])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(data_iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(nn.Linear(2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializing model parameters\n",
    "net[0].weight.data.normal_(0, 0.01)\n",
    "net[0].bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE loss\n",
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pytorch `optim` module contains stochastic gradient descent and a bunch of variations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = torch.optim.SGD(net.parameters(), lr=0.03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training loop has a similar logic To the manual implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0 , loss  0.00028297503013163805\n",
      "epoch  1 , loss  0.00010014433064498007\n",
      "epoch  2 , loss  0.00010028117685578763\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "for epoch in range(num_epochs): \n",
    "    for X, y in data_iter: \n",
    "        l = loss(net(X), y)\n",
    "        trainer.zero_grad()\n",
    "        l.backward()\n",
    "        trainer.step()\n",
    "    l = loss(net(features2), labels)\n",
    "    print(\"epoch \", epoch, \", loss \", float(l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These high-level features become especially useful when we start dealing with complicated networks. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
